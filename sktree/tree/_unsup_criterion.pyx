import numpy as np

cimport numpy as cnp

cnp.import_array()

cdef class UnsupervisedCriterion(BaseCriterion):
    """Abstract criterion for unsupervised learning.
    
    This object is a copy of the Criterion class of scikit-learn, but is used
    for unsupervised learning. However, ``Criterion`` in scikit-learn was
    designed for supervised learning, where the necessary
    ingredients to compute a split point is solely with y-labels. In
    this object, we subclass and instead rely on the X-data.    

    This object stores methods on how to calculate how good a split is using
    different metrics for unsupervised splitting.
    """
    def __cinit__(self):
        """Initialize attributes for unsupervised criterion.
        """
        self.start = 0
        self.pos = 0
        self.end = 0

        self.n_node_samples = 0
        self.weighted_n_node_samples = 0.0
        self.weighted_n_left = 0.0
        self.weighted_n_right = 0.0

        # Initialize count metric for current, going left and going right
        self.sum_total = 0.0
        self.sum_left = 0.0
        self.sum_right = 0.0

    cdef int init(
        self,
        const DTYPE_t[:,:] X,
        const DOUBLE_t[:] sample_weight,
        double weighted_n_samples,
        const SIZE_t[:] sample_indices
    ) nogil except -1:
        """Placehodler for a method which will initialize the unsuperivsed criterion

        Returns -1 in case of failure to allocate memory (and raise MemoryError)
        or 0 otherwise.

        Parameters
        ----------
        X : array-like, dtype=DTYPE_t
            The data-feature matrix stored as a buffer for memory efficiency. Note that
            this is not used, but simply passed as a convenience function.
        sample_weight : array-like, dtype=DOUBLE_t
            The weight of each sample (i.e. row of X).
        weighted_n_samples : double
            The total weight of all samples.
        """
        pass


cdef class TwoMeans(UnsupervisedCriterion):
    r"""Two means split impurity.

    The two means split finds the cutpoint that minimizes the one-dimensional
    2-means objective, which is finding the cutoff point where the total variance
    from cluster 1 and cluster 2 are minimal. 

    The mathematical optimization problem is to find the cutoff index ``s``,
    which is called 'pos' in scikit-learn.

        \min_s \sum_{i=1}^s (x_i - \hat{\mu}_1)^2 + \sum_{i=s+1}^N (x_i - \hat{\mu}_2)^2

    where x is a N-dimensional feature vector, N is the number of samples and the \mu
    terms are the estimated means of each cluster 1 and 2.

    Node-Wise Feature Generation
    ----------------------------
    URerF doesn't choose split points in the original feature space
    It follows the random projection framework

    \tilde{X}= A^T X'

    where, A is p x d matrix distributed as f_A, where f_A is the 
    projection distribution and d is the dimensionality of the 
    projected space. A is generated by randomly sampling from 
    {-1,+1} lpd times, then distributing these values uniformly 
    at random in A. l parameter is used to control the sparsity of A
    and is set to 1/20.

    Each of the d rows \tilde{X}[i; :], i \in {1,2,...d} is then 
    inspected for the best split point. The optimal split point and 
    splitting dimension are chosen according to which point/dimension
    pair minimizes the splitting criteria described in the following 
    section
    """
    cdef int init(
        self,
        const DTYPE_t[:,:] X,
        const DOUBLE_t[:] sample_weight,
        double weighted_n_samples,
        const SIZE_t[:] sample_indices
    ) nogil except -1:
        """Initialize the criterion.

        Returns -1 in case of failure to allocate memory (and raise MemoryError)
        or 0 otherwise.

        Parameters
        ----------
        X : array-like, dtype=DOUBLE_t
            The target stored as a buffer for memory efficiency. Note that
            this is not used, but simply passed as a convenience function.
        sample_weight : array-like, dtype=DOUBLE_t
            The weight of each sample (i.e. row of X).
        weighted_n_samples : double
            The total weight of all samples.
        samples : array-like, dtype=SIZE_t
            A mask on the samples, showing which ones we want to use
        """
        self.X = X
        self.sample_weight = sample_weight
        self.weighted_n_samples = weighted_n_samples
        self.sample_indices = sample_indices

        return 0
        
    cdef int reset(self) nogil except -1:
        """Reset the criterion at pos=start.

        Returns -1 in case of failure to allocate memory (and raise MemoryError)
        or 0 otherwise.
        """
        self.pos = self.start

        self.weighted_n_left = 0.0
        self.weighted_n_right = self.weighted_n_node_samples
        self.sum_left = 0.0
        self.sum_right = self.sum_total
        return 0

    cdef int reverse_reset(self) nogil except -1:
        """Reset the criterion at pos=end.

        Returns -1 in case of failure to allocate memory (and raise MemoryError)
        or 0 otherwise.
        """
        self.pos = self.end

        self.weighted_n_left = self.weighted_n_node_samples
        self.weighted_n_right = 0.0
        self.sum_right = 0.0
        self.sum_left = self.sum_total
        return 0

    cdef int update(self, SIZE_t new_pos) nogil except -1:
        """Updated statistics by moving samples[pos:new_pos] to the left child.

        Returns -1 in case of failure to allocate memory (and raise MemoryError)
        or 0 otherwise.

        Parameters
        ----------
        new_pos : SIZE_t
            The new ending position for which to move samples from the right
            child to the left child.
        """
        cdef SIZE_t pos = self.pos
        cdef SIZE_t end = self.end

        cdef const SIZE_t[:] sample_indices = self.sample_indices
        cdef const DOUBLE_t[:] sample_weight = self.sample_weight

        cdef SIZE_t i
        cdef SIZE_t p
        cdef DOUBLE_t w = 1.0

        # Update statistics up to new_pos
        #
        # Given that
        #   sum_left[x] +  sum_right[x] = sum_total[x]
        # and that sum_total is known, we are going to update
        # sum_left from the direction that require the least amount
        # of computations, i.e. from pos to new_pos or from end to new_po.
        if (new_pos - pos) <= (end - new_pos):
            for p in range(pos, new_pos):
                i = sample_indices[p]

                if sample_weight is not None:
                    w = sample_weight[i]

                self.sum_left += w * self.X[i]

                self.weighted_n_left += w
        else:
            self.reverse_reset()

            for p in range(end - 1, new_pos - 1, -1):
                i = sample_indices[p]

                if sample_weight is not None:
                    w = sample_weight[i]

                self.sum_left -= w * self.X[i]

                self.weighted_n_left -= w

        # Update right part statistics
        self.weighted_n_right = (self.weighted_n_node_samples - 
                                self.weighted_n_left)
        self.sum_right = self.sum_total - self.sum_left

        self.pos = new_pos
        return 0

    cdef double node_impurity(self) nogil:
        """Evaluate the impurity of the current node.

        Evaluate the TwoMeans criterion as impurity of the current node,
        i.e. the impurity of sample_indices[start:end]. The smaller the impurity the
        better.
        """
        cdef double impurity

        impurity = self._compute_variance(0, self.end) / self.weighted_n_node_samples

        return impurity

    cdef double _compute_variance(self, start, end) nogil:
        """Computes variance of left and right cluster at `pos`

        variance = weight * (left_impurity + right_impurity) / n_samples
        """
        cdef SIZE_t i
        cdef SIZE_t p
        cdef DOUBLE_t w = 1.0
        cdef SIZE_t n_samples = end - start

        cdef double var = 0.0 #variance
        cdef double mean = 0.0 #mean

        cdef const DTYPE_t[:,:] X = self.X
        
        #calculate the mean
        for p in range(start, end):
            i = self.sample_indices[p]

            mean += self.X[i] / n_samples

        #calculate variance
        for p in range(start, end):
            i = self.sample_indices[p]

            if self.sample_weight is not None:
                w = self.sample_weight[i]

            var += w * (X[i] - mean) * (X[i] - mean)

        return var / self.n_samples

    cdef void children_impurity(self, double* impurity_left,
                                    double* impurity_right) nogil:
       """Evaluate the impurity in children nodes.

        i.e. the impurity of the left child (samples[start:pos]) and the
        impurity the right child (samples[pos:end]).

        TODO:
        Review on TwoMeans specific methods: Good start, and it's def in the right direction.
        impurity in TwoMeans is defined as the Variance. 
        
        Variance formula would be 
        impurity = weight * (left_impurity + right_impurity) / n_samples 
        and then left_impurity and right_impurity are defined as: 
        weight * Variance of left child and weight * Variance of right child. 

        So you need to compute variance in node_impurity and children_impurity. 
        The only thing changing are the pointers.

        You should therefore define a separate function to compute variance.
        Focus on getting the Criterion correct and ping me w/ questions. We can move onto the splitter once this is done.

        Parameters
        ----------
        impurity_left : double pointer
            The memory address to save the impurity of the left node
        impurity_right : double pointer
            The memory address to save the impurity of the right node
        """
        cdef const DOUBLE_t[:] sample_weight = self.sample_weight
        cdef const SIZE_t[:] sample_indices = self.sample_indices
        cdef SIZE_t pos = self.pos
        cdef SIZE_t start = self.start

        cdef DOUBLE_t X_ik

        cdef double sq_sum_left = 0.0
        cdef double sq_sum_right

        cdef double mu_left = 0.0 #left cluster mean
        cdef double mu_right = 0.0 #right cluster mean

        cdef SIZE_t i
        cdef SIZE_t p
        cdef SIZE_t k
        cdef DOUBLE_t w = 1.0

        for p in range(start, pos):
            i = sample_indices[p]

            if sample_weight is not None:
                w = sample_weight[i]

            X_ik = self.X[i]
            sq_sum_left += w * X_ik

        sq_sum_right = self.sq_sum_total - sq_sum_left

        impurity_left[0] = sq_sum_left / self.weighted_n_left
        impurity_right[0] = sq_sum_right / self.weighted_n_right

        for k in range(self.n_outputs):
            impurity_left[0] -= (self.sum_left[k] / self.weighted_n_left) ** 2.0
            impurity_right[0] -= (self.sum_right[k] / self.weighted_n_right) ** 2.0

        impurity_left[0] /= self.n_outputs
        impurity_right[0] /= self.n_outputs
        
        # use left_sum and right_sum to calculate impurity?
        # or should this method take two separate Xs making up
        # left and right child nodes?
        #calculate left and right cluster's mean
        for p in range(end):
            i = self.sample_indices[p]

            if p < pos:
                mu_left += X[i] / self.n_samples
            else:
                mu_right += X[i] / self.n_samples

        #calculate variance
        for p in range(end):
            i = self.sample_indices[p]

            if self.sample_weight is not None:
                w = self.sample_weight[i]

            if k < pos:
                mean = mu_left
            else:
                mean = mu_right

            var += w * (X[i] - mean) * (X[i] - mean)

        return var / self.n_samples

        pass

    cdef void node_value(self, double* dest) nogil:
        r"""Set the node value with sum_total and save it into dest.

        Parameters
        ----------
        dest : double pointer
            The memory address which we will save the node value into.
        """
        memcpy(dest, &self.sum_total, sizeof(double))

    cdef void set_sample_pointers(
        self,
        SIZE_t start,
        SIZE_t end
    ) nogil:
        """Set sample pointers in the criterion."""
        self.n_node_samples = end - start
        self.start = start
        self.end = end
        self.sum_total = 0.0
        self.weighted_n_node_samples = 0.0

        cdef SIZE_t i
        cdef SIZE_t p

        cdef DOUBLE_t w = 1.0
        cdef DOUBLE_t X_i
        cdef DOUBLE_t W_X_i

        for p in range(start, end):
            i = self.sample_indices[p]

            # w is originally set to be 1.0, meaning that if no sample weights
            # are given, the default weight of each sample is 1.0.
            if self.sample_weight is not None:
                w = self.sample_weight[i]

            X_i = self.X[i]
            w_X_i = w * X_i
            self.sum_total += w_X_i
            self.weighted_n_node_samples += w

        # Reset to pos=start
        self.reset()